{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from scoring import Metrics\n",
    "from classification import Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = 'src'\n",
    "\n",
    "# Import data\n",
    "import_path = os.path.join(DIRPATH, 'export.npy')\n",
    "\n",
    "data = np.load (import_path)\n",
    "#data[:, :-1] = data[:, :-1]/255.  # normalise values\n",
    "vals_nb = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6949790, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test sets\n",
    "\n",
    "def create_sets(data, train_frac=0.05):\n",
    "\n",
    "    # Create (train, test)\n",
    "    data_shuffled = data.copy()\n",
    "\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(data_shuffled)\n",
    "\n",
    "    train_nb = int(vals_nb * train_frac)\n",
    "    # print(f'training on {train_nb} vals')\n",
    "\n",
    "    return data_shuffled[:train_nb], data_shuffled[train_nb:]\n",
    "\n",
    "data_train, data_test = create_sets(data, train_frac=0.3)\n",
    "\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Test image\n",
    "image_test_path = 'src/ima_1e8ccf23-d106-4227-908c-e4fbbb1da5f8.jpg'\n",
    "\n",
    "image_test = image_test_path.split('/')[-1]\n",
    "image_test_name, _ = os.path.splitext(image)\n",
    "id_test = image_test_name[4:]\n",
    "\n",
    "# Import and flatten test image\n",
    "image_test_path = os.path.join('src/sky-images', image)\n",
    "image_test_array = cv2.imread (image_test_path)\n",
    "image_test_shape = image_test_array.shape\n",
    "image_test_array_flat = image_test_array.reshape(-1, 1, 3)# / 255.\n",
    "image_test_array_flat = image_test_array_flat.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classifiers.lda import LDA\n",
    "\n",
    "RUN_LDA = False\n",
    "if RUN_LDA:\n",
    "    data_train_lda = data_train\n",
    "    data_test_lda  = data_test\n",
    "\n",
    "    # Train LDA\n",
    "    lda = LDA()\n",
    "    lda.fit (data_train_lda[:, :-1], data_train_lda[:, -1])\n",
    "\n",
    "    # Test LDA\n",
    "    pred_lda = lda.eval_batch(data_test_lda[:, :-1], verbose=False)\n",
    "    metrics_lda = Metrics(data_test_lda[:, -1], pred_lda)\n",
    "    print(metrics_lda)\n",
    "\n",
    "# F1 = 0.8913411645159924\n",
    "# dt = 1:37min (low power)\n",
    "\n",
    "# Test on test image\n",
    "image_test_pred = lda.eval_batch(image_test_array_flat, verbose=False)\n",
    "image_test_pred = image_test_pred.reshape(image_test_shape[:2])\n",
    "cv2.imwrite(f'output/{image_test_name}-pred.png', image_test_pred * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-39b41efe5c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train QDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mqda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mqda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train_qda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "### DEBUG QDA (implement more efficient algorithm)\n",
    "\n",
    "\n",
    "from classifiers.qda import QDA\n",
    "\n",
    "RUN_QDA = False\n",
    "if RUN_QDA:\n",
    "    data_train_qda = data_train\n",
    "    data_test_qda  = data_test[:10000]\n",
    "\n",
    "    # Train QDA\n",
    "    qda = QDA()\n",
    "    qda.fit (data_train_qda)\n",
    "\n",
    "    # Test QDA\n",
    "    pred_qda = qda.eval_batch(data_test_qda[:, :-1], verbose=False)\n",
    "    metrics_qda = Metrics(data_test_qda[:, -1], pred_qda)\n",
    "    print(metrics_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
